{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pradeep Elavarasan EIP3 Assignment4 Final Updated.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "96DlVuD06yKI",
        "oBebtKiP3AXh",
        "Dx3KtG4m8BDp",
        "_CHiOvRD1i2H",
        "jVcLM1QKj4V5",
        "BIG90j2qCtP7",
        "S0OngDM9Kz0p",
        "nsUT6mZG-LHQ",
        "1H5I5vHw_TcM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeepelavarasan/Image-Classification--Tiny-ImageNet/blob/master/Pradeep_Elavarasan_EIP3_Assignment4_Final_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96DlVuD06yKI",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6unbJSw6wW0",
        "colab_type": "code",
        "outputId": "c8eb4ebe-8be7-48f9-c5fd-57c791b2daa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import cv2\n",
        "\n",
        "#!pip uninstall keras-preprocessing\n",
        "#!pip install git+https://github.com/keras-team/keras-preprocessing.git\n",
        "\n",
        "import os\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import requests\n",
        "from io import StringIO\n",
        "from sklearn import preprocessing\n",
        "import tensorflow\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "from tensorflow.keras.callbacks import *\n",
        "\n",
        "import skimage\n",
        "\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import *\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Setting up  TPU ------------------------------\n",
        "\n",
        "import os\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  print(devices)\n",
        "  \n",
        "  tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.4.213.10:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 4313406809111492259), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4506753524439952341), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17784538767339841784), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 390743458509973771), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4248580409610210351), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9465965433712178690), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10770749135754516838), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1462807666267413378), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9875596676998249099), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16362100060385948876), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 6977783744482734265)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f9U1W6RVWFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBebtKiP3AXh",
        "colab_type": "text"
      },
      "source": [
        "# Loading data to Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzeC9Pp-i80_",
        "colab_type": "code",
        "outputId": "ed844bc1-2b72-41fc-bd9b-c0a873579974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lycZ5CzbjKTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip '/content/gdrive/My Drive/Assignment_4/tiny-imagenet-200.zip'\n",
        "\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/gdrive/My Drive/Assignment_4/tiny-imagenet-200.zip') as zf:\n",
        "  zf.extractall('/content')\n",
        "\n",
        "#ZipFile.extract(member = '/content/gdrive/My Drive/Assignment_4/tiny-imagenet-200.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx3KtG4m8BDp",
        "colab_type": "text"
      },
      "source": [
        "# Functions required for building custom RESNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ua2gCDDPuxd",
        "colab_type": "code",
        "outputId": "74f32c3f-3072-4d83-dd35-0591b4f109aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import six\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Lambda\n",
        ")\n",
        "from tensorflow.python.keras.layers.convolutional import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D\n",
        ")\n",
        "\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, concatenate, SeparableConv2D\n",
        "from tensorflow.python.keras.layers.merge import add\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    activation = Activation(\"relu\")(norm)\n",
        "    return activation\n",
        "    #return Dropout(0.2)(activation)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(filters=32):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        conv = SeparableConv2D(filters=filters, kernel_size=(3,3),\n",
        "                      strides=(1,1), padding=\"same\",\n",
        "                      kernel_initializer=\"he_normal\",\n",
        "                      kernel_regularizer=l2(1.e-4))(input)\n",
        "       \n",
        "        \n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\"\"\"\n",
        "def _bn_relu_conv(filters=32): # not used\n",
        "    #Helper to build a BN -> relu -> conv block.\n",
        "    #This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \n",
        "    \n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                      strides=strides, padding=\"same\",\n",
        "                      kernel_initializer=\"he_normal\",\n",
        "                      kernel_regularizer=l2(1.e-4))(activation)\n",
        "\n",
        "    return f\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    #Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "  \n",
        "     #Expand channels of shortcut to match residual.\n",
        "     #Stride appropriately to match residual (width, height)\n",
        "     #Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def basic_block(filters):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        conv1 = _conv_bn_relu(filters=filters)(input)\n",
        "        residual = _conv_bn_relu(filters=filters)(conv1)\n",
        "        #output = _shortcut(input, residual)\n",
        "        output = concatenate([input, residual])\n",
        "        return output\n",
        "\n",
        "\n",
        "    return f\n",
        "    \n",
        "\n",
        "\n",
        "def bottleneck(filters):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        bottleneck = Conv2D(filters=filters,\n",
        "                           kernel_size=(1, 1),\n",
        "                           strides=(1,1),\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        return _bn_relu(bottleneck)\n",
        "      \n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "  \n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.image_dim_ordering() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "        \n",
        "        #--------Initialization Block 0 \n",
        "        input = Input(shape=input_shape)\n",
        "        block0 = _conv_bn_relu(filters=32)(input)\n",
        "        block0 = basic_block(filters=64)(block0)\n",
        "        block0 = basic_block(filters=128)(block0)\n",
        "        block0 = basic_block(filters=256)(block0)\n",
        "        \n",
        "        # Intersection/Bottleneck Block 0\n",
        "        \n",
        "        bottleneck0 = bottleneck(filters=64)(block0)\n",
        "        skip_connection0 = bottleneck0 \n",
        "        \n",
        "        #--------Resnet Block 1 \n",
        "        \n",
        "        block1 = basic_block(filters=64)(bottleneck0)\n",
        "        block1 = basic_block(filters=128)(block1)\n",
        "        block1 = basic_block(filters=256)(block1)\n",
        "        block1 = basic_block(filters=512)(block1)\n",
        "\n",
        "        # Intersection/Bottleneck Block 1\n",
        "        \n",
        "        bottleneck1 = bottleneck(filters=128)(block1)\n",
        "        skip_connection1 = bottleneck1 \n",
        "        \n",
        "        #--------Resnet Block 2\n",
        "        block2 = concatenate([skip_connection0, skip_connection1])\n",
        "        block2 = basic_block(filters=128)(block2)\n",
        "        block2 = basic_block(filters=256)(block2)\n",
        "        block2 = basic_block(filters=512)(block2)\n",
        "        block2 = basic_block(filters=1024)(block2)\n",
        "\n",
        "        # Intersection/Bottleneck Block 2\n",
        "        \n",
        "        bottleneck2 = bottleneck(filters=256)(block2)\n",
        "        skip_connection2 = bottleneck2 \n",
        "        \n",
        "        #--------Resnet Block 3 \n",
        "        block3 = concatenate([skip_connection0, skip_connection1, skip_connection2])\n",
        "        block3 = basic_block(filters=256)(block3)\n",
        "        block3 = basic_block(filters=512)(block3)\n",
        "        block3 = basic_block(filters=512)(block3)\n",
        "        block3 = basic_block(filters=1024)(block3)\n",
        "\n",
        "        # Intersection/Bottleneck Block 3\n",
        "        \n",
        "        bottleneck3 = bottleneck(filters=256)(block3)\n",
        "        skip_connection3 = bottleneck3 \n",
        "        \n",
        "        #--------Resnet Block 4 \n",
        "        \n",
        "        block4 = concatenate([skip_connection0, skip_connection1, skip_connection2, skip_connection3])\n",
        "        block4= MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\", name=\"Maxpool\")(block4)\n",
        "        block4 = basic_block(filters=256)(block4)\n",
        "        block4 = basic_block(filters=512)(block4)\n",
        "\n",
        "        # Intersection/Bottleneck Block 4\n",
        "        \n",
        "        bottleneck4 = bottleneck(filters=200)(block4)\n",
        "        \n",
        "        # Global Average pooling\n",
        "        gap = GlobalAveragePooling2D()(bottleneck4)\n",
        "\n",
        "        #Softmax\n",
        "        output = Activation('softmax')(gap)\n",
        "\n",
        "        model = Model(inputs=input, outputs=output)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 0, 0])\n",
        "    @staticmethod\n",
        "    def build_custom_resnet(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [4, 4, 5, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CHiOvRD1i2H",
        "colab_type": "text"
      },
      "source": [
        "# Data Generator Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jomD_BSsoBRA",
        "colab_type": "text"
      },
      "source": [
        "***Additional Data Augmentation using IMGAUG***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLqgmmEAoHpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "\n",
        "#aug1 = iaa.GaussianBlur(sigma=(0, 2.0))\n",
        "#aug2 = iaa.AdditiveGaussianNoise(scale=0.20 * 255)\n",
        "aug3 = iaa.ChannelShuffle(p=1.0)\n",
        "#aug4 = iaa.AddToHueAndSaturation((-50,50))\n",
        "#aug5 = iaa.GammaContrast((0.5,1.75),per_channel=True)\n",
        "#aug6 = PadToFixedSize(height'=height+32',width'=width+32', position='center')\n",
        "aug7 = iaa.CoarseDropout(p=0.2, size_percent=0.02)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def additional_augmenation(image):\n",
        "    #image = aug1.augment_image(image)\n",
        "    #image = aug2.augment_image(image)\n",
        "    image = aug3.augment_image(image)\n",
        "    #image = aug4.augment_image(image)\n",
        "    image = aug7.augment_image(image)\n",
        "    #image = skimage.exposure.rescale_intensity(aug5.augment_image(image),in_range=(0, 255))\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLihBIbMoJO3",
        "colab_type": "text"
      },
      "source": [
        "**Loading of training and validation data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhHWLEOk1iLF",
        "colab_type": "code",
        "outputId": "78aa05b5-8b7b-49b0-a661-f9506ae64cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "       #featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "      # samplewise_center=False,  # set each sample mean to 0\n",
        "      #  featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "      #  samplewise_std_normalization=False,  # divide each input by its std\n",
        "      #  zca_whitening=False,  # apply ZCA whitening\n",
        "      #  rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "      #  width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "       # height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        zoom_range=[0.5, 1.5], #zoom\n",
        "      #  vertical_flip=False, # randomly flip images\n",
        "        rescale= 1./255,\n",
        "        preprocessing_function=additional_augmenation)  \n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=\"./tiny-imagenet-200/train/\",\n",
        "    target_size=(32, 32),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=250,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITa2q6T87xmt",
        "colab_type": "code",
        "outputId": "29b77ff0-7efd-43ea-b90f-c7bb45a1ab45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "val_data = pd.read_csv(\"./tiny-imagenet-200/val/val_annotations.txt\", sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "\n",
        "valid_datagen=ImageDataGenerator(rescale= 1./255)\n",
        "valid_generator=valid_datagen.flow_from_dataframe(dataframe=val_data, directory=\"./tiny-imagenet-200/val/images/\", x_col=\"File\", y_col=\"Class\", class_mode=\"categorical\",validate_filenames=False, target_size=(32,32), batch_size=250,seed=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVcLM1QKj4V5",
        "colab_type": "text"
      },
      "source": [
        "# **Few Training Initializations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELLTI0wRje2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "\n",
        "#lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), cooldown=0,verbose=1, patience=10, min_lr=0.5e-6)\n",
        "#early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
        "\n",
        "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz0RaPsfJpii",
        "colab_type": "text"
      },
      "source": [
        "**Setting up Model weights back mechanism**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNRA9h9xJkKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import *\n",
        "filepath=\"/content/gdrive/My Drive/Assignment_4/Training_Backup/V34-epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIG90j2qCtP7",
        "colab_type": "text"
      },
      "source": [
        "# Model Training on 32*32 Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A-lSXsYcyIQ",
        "colab_type": "text"
      },
      "source": [
        "**Model building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrzWQmHUcyUT",
        "colab_type": "code",
        "outputId": "0a69a1a5-7d0a-4348-a28a-35c85174db33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5474
        }
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "# The imagenet images are RGB.\n",
        "nb_classes = 200\n",
        "img_channels = 3\n",
        "\n",
        "model = ResnetBuilder.build_custom_resnet((img_channels, img_rows, img_cols), nb_classes)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 32, 32, 32)   155         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 32, 32, 32)   128         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 32, 32, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 32, 32, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 32, 32, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 32, 32, 64)   256         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 96)   0           activation[0][0]                 \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 32, 32, 128)  13280       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 32, 32, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 32, 32, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 32, 32, 128)  512         separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 224)  0           concatenate[0][0]                \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 32, 32, 256)  59616       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 32, 32, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 256)  0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 32, 32, 256)  1024        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 256)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 480)  0           concatenate_1[0][0]              \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   30784       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 64)   4736        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 32, 32, 64)   256         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 32, 32, 64)   4736        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 32, 32, 64)   256         separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 128)  0           activation_7[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 32, 32, 128)  17664       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 32, 32, 128)  512         separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 128)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 32, 32, 128)  17664       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 32, 32, 128)  512         separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 256)  0           concatenate_3[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 32, 32, 256)  68096       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 32, 32, 256)  1024        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 32, 32, 256)  68096       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 32, 32, 256)  1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           concatenate_4[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 32, 32, 512)  267264      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 32, 32, 512)  2048        separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 32, 32, 512)  267264      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 32, 32, 512)  2048        separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 1024) 0           concatenate_5[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 128)  131200      concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 32, 32, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 128)  0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 192)  0           activation_7[0][0]               \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 32, 32, 128)  26432       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 32, 32, 128)  512         separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 128)  0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 32, 32, 128)  17664       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 32, 32, 128)  512         separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 128)  0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 320)  0           concatenate_7[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 32, 32, 256)  85056       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 32, 32, 256)  1024        separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 32, 32, 256)  68096       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 32, 32, 256)  1024        separable_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 576)  0           concatenate_8[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 32, 32, 512)  300608      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 32, 32, 512)  2048        separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 32, 32, 512)  267264      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 32, 32, 512)  2048        separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 1088) 0           concatenate_9[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 32, 32, 1024) 1124928     concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 32, 32, 1024) 4096        separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 32, 32, 1024) 1058816     activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 32, 32, 1024) 4096        separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 2112) 0           concatenate_10[0][0]             \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 256)  540928      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 448)  0           activation_7[0][0]               \n",
            "                                                                 activation_16[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 32, 32, 256)  118976      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 32, 32, 256)  1024        separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 32, 32, 256)  68096       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 32, 32, 256)  1024        separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 704)  0           concatenate_12[0][0]             \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 32, 32, 512)  367296      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 32, 32, 512)  2048        separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 32, 32, 512)  267264      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 32, 32, 512)  2048        separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 1216) 0           concatenate_13[0][0]             \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 32, 32, 512)  634048      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 32, 32, 512)  2048        separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 32, 32, 512)  267264      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 32, 32, 512)  2048        separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 1728) 0           concatenate_14[0][0]             \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 32, 32, 1024) 1786048     concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 32, 32, 1024) 4096        separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 32, 32, 1024) 1058816     activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 32, 32, 1024) 4096        separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 32, 32, 2752) 0           concatenate_15[0][0]             \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 256)  704768      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 32, 32, 704)  0           activation_7[0][0]               \n",
            "                                                                 activation_16[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Maxpool (MaxPooling2D)          (None, 16, 16, 704)  0           concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 16, 16, 256)  186816      Maxpool[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 16, 16, 256)  1024        separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 256)  0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 16, 16, 256)  68096       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 16, 16, 256)  1024        separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 256)  0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 960)  0           Maxpool[0][0]                    \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 16, 16, 512)  500672      concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 16, 16, 512)  2048        separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 512)  0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 16, 16, 512)  267264      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 16, 16, 512)  2048        separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 512)  0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 1472) 0           concatenate_18[0][0]             \n",
            "                                                                 activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 200)  294600      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 16, 16, 200)  800         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 200)  0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 11,178,211\n",
            "Trainable params: 11,150,739\n",
            "Non-trainable params: 27,472\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HFL_GHkQBD",
        "colab_type": "text"
      },
      "source": [
        "**Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rvILlcJgi9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = tf.train.AdamOptimizer(0.001)\n",
        "\n",
        "#adam = tf.keras.Adam(learning_rate=0.001)\n",
        "\n",
        "#adam = tf.keras.optimizers.Adam(lr=0.001) \n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCsm9ccWV0FL",
        "colab_type": "code",
        "outputId": "ae97d379-1686-4741-aa4a-0c9276476522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.62.229.122:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1409611887889514383)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9204565535668976996)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11178418307169434886)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10400178205859286484)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12142905713005483816)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13088328604718237284)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18014065711952977552)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5221929450171556440)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3776946742147440046)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6989457801135434240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 7280724931402440402)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CmHNelFz7sx",
        "colab_type": "text"
      },
      "source": [
        "**Training with 32*32 epoch 1-25**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8CY09w3z71n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/V28_desnse-epochs:023-val_acc:0.476.hdf5\")\n",
        "#model = load_model(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/V4-TPU-resnet50-epochs:002-val_acc:0.168.hdf5\")\n",
        "last_executed_epoch = 0\n",
        "nb_epoch = 25\n",
        "csv_logger = CSVLogger('Assignment4_V34_32x32_1_25.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5vW9mWvVaaG",
        "colab_type": "code",
        "outputId": "f108bbeb-4ea8-4394-bba8-9ac1a9be15b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1550
        }
      },
      "source": [
        "    print('Training on 32*32 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    #model.fit_generator(generator=train_generator,\n",
        "     #                   steps_per_epoch=STEP_SIZE_TRAIN,               \n",
        "      #                  epochs=nb_epoch,\n",
        "       #                 initial_epoch=last_executed_epoch,verbose=1)\n",
        "    \n",
        "    \n",
        "    model.fit_generator(generator=train_generator,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                        validation_data=valid_generator,\n",
        "                        validation_steps=STEP_SIZE_VALID,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "    \n",
        "    model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_1_25.hdf5\")\n",
        "    !cp \"Assignment4_V34_32x32_1_25.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_1_25.csv\"\n",
        "    print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 32*32 images: Epochs 1 - 25 : \n",
            "Epoch 1/25\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(31,), dtype=tf.int32, name='core_id_20'), TensorSpec(shape=(31, 32, 32, 3), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(31, 200), dtype=tf.float32, name='activation_81_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 86.66216588020325 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "399/400 [============================>.] - ETA: 1s - loss: 5.0722 - acc: 0.0369INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(31,), dtype=tf.int32, name='core_id_30'), TensorSpec(shape=(31, 32, 32, 3), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(31, 200), dtype=tf.float32, name='activation_81_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 48.6318724155426 secs\n",
            "40/40 [==============================] - 59s 1s/step - loss: 5.5371 - acc: 0.0049\n",
            "400/400 [==============================] - 609s 2s/step - loss: 5.0715 - acc: 0.0369 - val_loss: 5.5371 - val_acc: 0.0049\n",
            "Epoch 2/25\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 4.9677 - acc: 0.0547\n",
            "400/400 [==============================] - 349s 872ms/step - loss: 4.6590 - acc: 0.0762 - val_loss: 4.9677 - val_acc: 0.0547\n",
            "Epoch 3/25\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 4.4709 - acc: 0.1059\n",
            "400/400 [==============================] - 350s 874ms/step - loss: 4.4177 - acc: 0.1087 - val_loss: 4.4709 - val_acc: 0.1059\n",
            "Epoch 4/25\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 4.7440 - acc: 0.1073\n",
            "400/400 [==============================] - 352s 879ms/step - loss: 4.2166 - acc: 0.1355 - val_loss: 4.7440 - val_acc: 0.1073\n",
            "Epoch 5/25\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 4.3982 - acc: 0.1173\n",
            "400/400 [==============================] - 351s 877ms/step - loss: 4.0505 - acc: 0.1594 - val_loss: 4.3982 - val_acc: 0.1173\n",
            "Epoch 6/25\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 4.4742 - acc: 0.1316\n",
            "400/400 [==============================] - 351s 876ms/step - loss: 3.9120 - acc: 0.1813 - val_loss: 4.4742 - val_acc: 0.1316\n",
            "Epoch 7/25\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 4.0236 - acc: 0.1816\n",
            "400/400 [==============================] - 349s 873ms/step - loss: 3.7904 - acc: 0.2001 - val_loss: 4.0236 - val_acc: 0.1816\n",
            "Epoch 8/25\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 3.7482 - acc: 0.2118\n",
            "400/400 [==============================] - 351s 878ms/step - loss: 3.6909 - acc: 0.2151 - val_loss: 3.7482 - val_acc: 0.2118\n",
            "Epoch 9/25\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 3.7333 - acc: 0.2239\n",
            "400/400 [==============================] - 350s 876ms/step - loss: 3.5893 - acc: 0.2337 - val_loss: 3.7333 - val_acc: 0.2239\n",
            "Epoch 10/25\n",
            "40/40 [==============================] - 10s 256ms/step - loss: 3.7730 - acc: 0.2200\n",
            "400/400 [==============================] - 350s 876ms/step - loss: 3.5069 - acc: 0.2462 - val_loss: 3.7730 - val_acc: 0.2200\n",
            "Epoch 11/25\n",
            "40/40 [==============================] - 10s 256ms/step - loss: 3.4502 - acc: 0.2683\n",
            "400/400 [==============================] - 351s 878ms/step - loss: 3.4300 - acc: 0.2591 - val_loss: 3.4502 - val_acc: 0.2683\n",
            "Epoch 12/25\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 4.2491 - acc: 0.1748\n",
            "400/400 [==============================] - 349s 874ms/step - loss: 3.3618 - acc: 0.2705 - val_loss: 4.2491 - val_acc: 0.1748\n",
            "Epoch 13/25\n",
            "40/40 [==============================] - 10s 255ms/step - loss: 3.5155 - acc: 0.2665\n",
            "400/400 [==============================] - 350s 874ms/step - loss: 3.2987 - acc: 0.2835 - val_loss: 3.5155 - val_acc: 0.2665\n",
            "Epoch 14/25\n",
            "40/40 [==============================] - 10s 256ms/step - loss: 3.8028 - acc: 0.2388\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 3.2411 - acc: 0.2924 - val_loss: 3.8028 - val_acc: 0.2388\n",
            "Epoch 15/25\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 3.1775 - acc: 0.3236\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 3.1817 - acc: 0.3052 - val_loss: 3.1775 - val_acc: 0.3236\n",
            "Epoch 16/25\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 3.1934 - acc: 0.3230\n",
            "400/400 [==============================] - 349s 874ms/step - loss: 3.1342 - acc: 0.3121 - val_loss: 3.1934 - val_acc: 0.3230\n",
            "Epoch 17/25\n",
            "40/40 [==============================] - 10s 257ms/step - loss: 3.1301 - acc: 0.3353\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 3.0823 - acc: 0.3229 - val_loss: 3.1301 - val_acc: 0.3353\n",
            "Epoch 18/25\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 3.6231 - acc: 0.2763\n",
            "400/400 [==============================] - 349s 873ms/step - loss: 3.0387 - acc: 0.3300 - val_loss: 3.6231 - val_acc: 0.2763\n",
            "Epoch 19/25\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 3.1427 - acc: 0.3342\n",
            "400/400 [==============================] - 349s 874ms/step - loss: 2.9898 - acc: 0.3431 - val_loss: 3.1427 - val_acc: 0.3342\n",
            "Epoch 20/25\n",
            "40/40 [==============================] - 10s 254ms/step - loss: 3.5706 - acc: 0.2871\n",
            "400/400 [==============================] - 353s 882ms/step - loss: 2.9504 - acc: 0.3483 - val_loss: 3.5706 - val_acc: 0.2871\n",
            "Epoch 21/25\n",
            "40/40 [==============================] - 10s 258ms/step - loss: 3.1294 - acc: 0.3317\n",
            "400/400 [==============================] - 351s 878ms/step - loss: 2.9162 - acc: 0.3535 - val_loss: 3.1294 - val_acc: 0.3317\n",
            "Epoch 22/25\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 3.3803 - acc: 0.3080\n",
            "400/400 [==============================] - 353s 882ms/step - loss: 2.8722 - acc: 0.3622 - val_loss: 3.3803 - val_acc: 0.3080\n",
            "Epoch 23/25\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 3.3995 - acc: 0.3083\n",
            "400/400 [==============================] - 352s 879ms/step - loss: 2.8328 - acc: 0.3710 - val_loss: 3.3995 - val_acc: 0.3083\n",
            "Epoch 24/25\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 2.9142 - acc: 0.3755\n",
            "400/400 [==============================] - 352s 879ms/step - loss: 2.8025 - acc: 0.3754 - val_loss: 2.9142 - val_acc: 0.3755\n",
            "Epoch 25/25\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 3.0814 - acc: 0.3608\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 2.7728 - acc: 0.3806 - val_loss: 3.0814 - val_acc: 0.3608\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbKJvDWrf30p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9Gmhi1SLtg",
        "colab_type": "text"
      },
      "source": [
        "**Training with 32*32 epoch 26-50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz7ZfcfjSL_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_1_25.hdf5\")\n",
        "last_executed_epoch = 25\n",
        "nb_epoch = 50\n",
        "csv_logger = CSVLogger('Assignment4_V34_32x32_26_50.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCB0_MBSSTTj",
        "colab_type": "code",
        "outputId": "8085fd4e-bf2f-4aa2-d01d-9e655636b0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "source": [
        "    print('Training on 32*32 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    #model.fit_generator(generator=train_generator,\n",
        "     #                   steps_per_epoch=STEP_SIZE_TRAIN,               \n",
        "      #                  epochs=nb_epoch,\n",
        "       #                 initial_epoch=last_executed_epoch,verbose=1)\n",
        "    \n",
        "    \n",
        "    model.fit_generator(generator=train_generator,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                        validation_data=valid_generator,\n",
        "                        validation_steps=STEP_SIZE_VALID,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "    model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_26_50.hdf5\")\n",
        "    !cp \"Assignment4_V34_32x32_26_50.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_26_50.csv\"\n",
        "    print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 32*32 images: Epochs 26 - 50 : \n",
            "Epoch 26/50\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 3.4582 - acc: 0.3086\n",
            "400/400 [==============================] - 352s 880ms/step - loss: 2.7419 - acc: 0.3884 - val_loss: 3.4582 - val_acc: 0.3086\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 3.1029 - acc: 0.3649\n",
            "400/400 [==============================] - 351s 877ms/step - loss: 2.7085 - acc: 0.3936 - val_loss: 3.1029 - val_acc: 0.3649\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 3.0603 - acc: 0.3620\n",
            "400/400 [==============================] - 352s 881ms/step - loss: 2.6837 - acc: 0.3987 - val_loss: 3.0603 - val_acc: 0.3620\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 3.0632 - acc: 0.3641\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 2.6516 - acc: 0.4054 - val_loss: 3.0632 - val_acc: 0.3641\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 2.8576 - acc: 0.3908\n",
            "400/400 [==============================] - 349s 871ms/step - loss: 2.6240 - acc: 0.4119 - val_loss: 2.8576 - val_acc: 0.3908\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 3.1826 - acc: 0.3495\n",
            "400/400 [==============================] - 348s 870ms/step - loss: 2.6028 - acc: 0.4152 - val_loss: 3.1826 - val_acc: 0.3495\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 3.0107 - acc: 0.3731\n",
            "400/400 [==============================] - 349s 873ms/step - loss: 2.5802 - acc: 0.4204 - val_loss: 3.0107 - val_acc: 0.3731\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 10s 259ms/step - loss: 3.2385 - acc: 0.3454\n",
            "400/400 [==============================] - 350s 874ms/step - loss: 2.5558 - acc: 0.4239 - val_loss: 3.2385 - val_acc: 0.3454\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 3.0432 - acc: 0.3726\n",
            "400/400 [==============================] - 351s 877ms/step - loss: 2.5258 - acc: 0.4310 - val_loss: 3.0432 - val_acc: 0.3726\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 2.9510 - acc: 0.3947\n",
            "400/400 [==============================] - 351s 877ms/step - loss: 2.5063 - acc: 0.4353 - val_loss: 2.9510 - val_acc: 0.3947\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 2.7492 - acc: 0.4181\n",
            "400/400 [==============================] - 350s 874ms/step - loss: 2.4863 - acc: 0.4369 - val_loss: 2.7492 - val_acc: 0.4181\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 2.9004 - acc: 0.3967\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 2.4607 - acc: 0.4441 - val_loss: 2.9004 - val_acc: 0.3967\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 10s 261ms/step - loss: 2.9971 - acc: 0.3861\n",
            "400/400 [==============================] - 349s 873ms/step - loss: 2.4450 - acc: 0.4480 - val_loss: 2.9971 - val_acc: 0.3861\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 3.0542 - acc: 0.3764\n",
            "400/400 [==============================] - 349s 873ms/step - loss: 2.4176 - acc: 0.4538 - val_loss: 3.0542 - val_acc: 0.3764\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 2.9784 - acc: 0.3902\n",
            "400/400 [==============================] - 351s 877ms/step - loss: 2.3900 - acc: 0.4596 - val_loss: 2.9784 - val_acc: 0.3902\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 3.1547 - acc: 0.3714\n",
            "400/400 [==============================] - 351s 877ms/step - loss: 2.3806 - acc: 0.4601 - val_loss: 3.1547 - val_acc: 0.3714\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 2.8017 - acc: 0.4187\n",
            "400/400 [==============================] - 349s 872ms/step - loss: 2.3525 - acc: 0.4658 - val_loss: 2.8017 - val_acc: 0.4187\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 2.9623 - acc: 0.4040\n",
            "400/400 [==============================] - 351s 879ms/step - loss: 2.3376 - acc: 0.4687 - val_loss: 2.9623 - val_acc: 0.4040\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 3.0157 - acc: 0.3932\n",
            "400/400 [==============================] - 350s 876ms/step - loss: 2.3166 - acc: 0.4757 - val_loss: 3.0157 - val_acc: 0.3932\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 2.8183 - acc: 0.4200\n",
            "400/400 [==============================] - 350s 874ms/step - loss: 2.3075 - acc: 0.4772 - val_loss: 2.8183 - val_acc: 0.4200\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 12s 293ms/step - loss: 2.9391 - acc: 0.4039\n",
            "400/400 [==============================] - 351s 878ms/step - loss: 2.2887 - acc: 0.4781 - val_loss: 2.9391 - val_acc: 0.4039\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 2.8572 - acc: 0.4159\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 2.2679 - acc: 0.4829 - val_loss: 2.8572 - val_acc: 0.4159\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 12s 290ms/step - loss: 2.8247 - acc: 0.4253\n",
            "400/400 [==============================] - 351s 879ms/step - loss: 2.2494 - acc: 0.4882 - val_loss: 2.8247 - val_acc: 0.4253\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 2.9810 - acc: 0.3984\n",
            "400/400 [==============================] - 350s 874ms/step - loss: 2.2280 - acc: 0.4925 - val_loss: 2.9810 - val_acc: 0.3984\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 2.7735 - acc: 0.4311\n",
            "400/400 [==============================] - 350s 875ms/step - loss: 2.2149 - acc: 0.4950 - val_loss: 2.7735 - val_acc: 0.4311\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHtLqFke6hL5",
        "colab_type": "text"
      },
      "source": [
        "**Training with 32*32 epoch 51-70**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf8MBIXE6hbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_26_50.hdf5\")\n",
        "last_executed_epoch = 50\n",
        "nb_epoch = 70\n",
        "csv_logger = CSVLogger('Assignment4_V34_32x32_51_75.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5kbRG7A6hk4",
        "colab_type": "code",
        "outputId": "4d8eec2f-a895-4941-f044-d1c3553bf3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1397
        }
      },
      "source": [
        "    print('Training on 32*32 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    #model.fit_generator(generator=train_generator,\n",
        "     #                   steps_per_epoch=STEP_SIZE_TRAIN,               \n",
        "      #                  epochs=nb_epoch,\n",
        "       #                 initial_epoch=last_executed_epoch,verbose=1)\n",
        "    \n",
        "    \n",
        "    model.fit_generator(generator=train_generator,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                        validation_data=valid_generator,\n",
        "                        validation_steps=STEP_SIZE_VALID,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "    model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_51_70.hdf5\")\n",
        "    !cp \"Assignment4_V34_32x32_51_75.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_51_75.csv\"\n",
        "    print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 32*32 images: Epochs 51 - 70 : \n",
            "Epoch 51/70\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(31,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(31, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(31, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 60.4656617641449 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "399/400 [============================>.] - ETA: 1s - loss: 2.2002 - acc: 0.4974INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(31,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(31, 32, 32, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(31, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 24.144737243652344 secs\n",
            "40/40 [==============================] - 33s 833ms/step - loss: 2.7717 - acc: 0.4362\n",
            "400/400 [==============================] - 525s 1s/step - loss: 2.1997 - acc: 0.4975 - val_loss: 2.7717 - val_acc: 0.4362\n",
            "Epoch 52/70\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 3.0451 - acc: 0.4054\n",
            "400/400 [==============================] - 346s 866ms/step - loss: 2.1789 - acc: 0.5024 - val_loss: 3.0451 - val_acc: 0.4054\n",
            "Epoch 53/70\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 2.8900 - acc: 0.4182\n",
            "400/400 [==============================] - 346s 866ms/step - loss: 2.1673 - acc: 0.5045 - val_loss: 2.8900 - val_acc: 0.4182\n",
            "Epoch 54/70\n",
            "40/40 [==============================] - 11s 268ms/step - loss: 2.7827 - acc: 0.4446\n",
            "400/400 [==============================] - 346s 864ms/step - loss: 2.1518 - acc: 0.5082 - val_loss: 2.7827 - val_acc: 0.4446\n",
            "Epoch 55/70\n",
            "40/40 [==============================] - 11s 274ms/step - loss: 3.0739 - acc: 0.3944\n",
            "400/400 [==============================] - 347s 866ms/step - loss: 2.1317 - acc: 0.5123 - val_loss: 3.0739 - val_acc: 0.3944\n",
            "Epoch 56/70\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 3.1267 - acc: 0.4041\n",
            "400/400 [==============================] - 346s 865ms/step - loss: 2.1201 - acc: 0.5154 - val_loss: 3.1267 - val_acc: 0.4041\n",
            "Epoch 57/70\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 2.7238 - acc: 0.4442\n",
            "400/400 [==============================] - 346s 865ms/step - loss: 2.1070 - acc: 0.5180 - val_loss: 2.7238 - val_acc: 0.4442\n",
            "Epoch 58/70\n",
            "40/40 [==============================] - 11s 270ms/step - loss: 2.6615 - acc: 0.4565\n",
            "400/400 [==============================] - 347s 868ms/step - loss: 2.0923 - acc: 0.5213 - val_loss: 2.6615 - val_acc: 0.4565\n",
            "Epoch 59/70\n",
            "40/40 [==============================] - 11s 272ms/step - loss: 2.7972 - acc: 0.4419\n",
            "400/400 [==============================] - 347s 867ms/step - loss: 2.0642 - acc: 0.5268 - val_loss: 2.7972 - val_acc: 0.4419\n",
            "Epoch 60/70\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 2.7333 - acc: 0.4437\n",
            "400/400 [==============================] - 347s 866ms/step - loss: 2.0557 - acc: 0.5275 - val_loss: 2.7333 - val_acc: 0.4437\n",
            "Epoch 61/70\n",
            "40/40 [==============================] - 10s 262ms/step - loss: 2.8116 - acc: 0.4391\n",
            "400/400 [==============================] - 346s 866ms/step - loss: 2.0416 - acc: 0.5320 - val_loss: 2.8116 - val_acc: 0.4391\n",
            "Epoch 62/70\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 2.9652 - acc: 0.4093\n",
            "400/400 [==============================] - 346s 865ms/step - loss: 2.0387 - acc: 0.5319 - val_loss: 2.9652 - val_acc: 0.4093\n",
            "Epoch 63/70\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 2.9121 - acc: 0.4191\n",
            "400/400 [==============================] - 345s 862ms/step - loss: 2.0153 - acc: 0.5387 - val_loss: 2.9121 - val_acc: 0.4191\n",
            "Epoch 64/70\n",
            "40/40 [==============================] - 10s 260ms/step - loss: 2.7606 - acc: 0.4421\n",
            "400/400 [==============================] - 343s 859ms/step - loss: 2.0104 - acc: 0.5382 - val_loss: 2.7606 - val_acc: 0.4421\n",
            "Epoch 65/70\n",
            "40/40 [==============================] - 11s 265ms/step - loss: 2.8586 - acc: 0.4365\n",
            "400/400 [==============================] - 345s 864ms/step - loss: 1.9827 - acc: 0.5447 - val_loss: 2.8586 - val_acc: 0.4365\n",
            "Epoch 66/70\n",
            "40/40 [==============================] - 11s 266ms/step - loss: 2.8027 - acc: 0.4484\n",
            "400/400 [==============================] - 345s 862ms/step - loss: 1.9758 - acc: 0.5434 - val_loss: 2.8027 - val_acc: 0.4484\n",
            "Epoch 67/70\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 3.0205 - acc: 0.4129\n",
            "400/400 [==============================] - 346s 865ms/step - loss: 1.9650 - acc: 0.5480 - val_loss: 3.0205 - val_acc: 0.4129\n",
            "Epoch 68/70\n",
            "40/40 [==============================] - 11s 264ms/step - loss: 3.0341 - acc: 0.4096\n",
            "400/400 [==============================] - 345s 863ms/step - loss: 1.9484 - acc: 0.5529 - val_loss: 3.0341 - val_acc: 0.4096\n",
            "Epoch 69/70\n",
            "40/40 [==============================] - 10s 260ms/step - loss: 2.8413 - acc: 0.4398\n",
            "400/400 [==============================] - 344s 859ms/step - loss: 1.9325 - acc: 0.5538 - val_loss: 2.8413 - val_acc: 0.4398\n",
            "Epoch 70/70\n",
            "40/40 [==============================] - 11s 263ms/step - loss: 2.9193 - acc: 0.4323\n",
            "400/400 [==============================] - 344s 859ms/step - loss: 1.9215 - acc: 0.5586 - val_loss: 2.9193 - val_acc: 0.4323\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0OngDM9Kz0p",
        "colab_type": "text"
      },
      "source": [
        "# Model Training on 64*64 images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCo72cA692On",
        "colab_type": "text"
      },
      "source": [
        "**Generation of 64*64 images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn6D7kIpTYNl",
        "colab_type": "code",
        "outputId": "58394331-acc0-41cf-8f5c-c19a4d605a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_generator_64 = train_datagen.flow_from_directory(\n",
        "    directory=\"./tiny-imagenet-200/train/\",\n",
        "    target_size=(64, 64),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=128,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=1\n",
        ")\n",
        "valid_generator_64=valid_datagen.flow_from_dataframe(dataframe=val_data, directory=\"./tiny-imagenet-200/val/images/\", x_col=\"File\", y_col=\"Class\", class_mode=\"categorical\",validate_filenames=False, shuffle=True, target_size=(64,64), batch_size=128,seed=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdV9-shXNZEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEP_SIZE_TRAIN_64 = train_generator_64.n//train_generator_64.batch_size\n",
        "STEP_SIZE_VALID_64 = valid_generator_64.n//valid_generator_64.batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX8R1g_R-C6C",
        "colab_type": "text"
      },
      "source": [
        "**Rebuilding the model to accept 64*64 images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9C7PZ0LHfd",
        "colab_type": "code",
        "outputId": "5172a1a9-5979-4d4e-f6a3-d918c8bc55dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5474
        }
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "# The imagenet images are RGB.\n",
        "nb_classes = 200\n",
        "img_channels = 3\n",
        "\n",
        "model = ResnetBuilder.build_custom_resnet((img_channels, img_rows, img_cols), nb_classes)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 64, 64, 32)   155         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 64, 64, 32)   128         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 64, 64, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 64, 64, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 64, 64, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 64, 64, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 64, 64, 64)   256         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 64, 96)   0           activation[0][0]                 \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 64, 64, 128)  13280       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 64, 64, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 64, 64, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 64, 64, 128)  512         separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 224)  0           concatenate[0][0]                \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 64, 64, 256)  59616       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 64, 64, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 256)  0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 64, 64, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 64, 64, 256)  1024        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 480)  0           concatenate_1[0][0]              \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 64, 64, 64)   30784       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 64, 64, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 64, 64, 64)   4736        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 64, 64, 64)   256         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 64, 64, 64)   4736        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 64, 64, 64)   256         separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 64)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64, 64, 128)  0           activation_7[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 64, 64, 128)  17664       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 64, 64, 128)  512         separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 64, 128)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 64, 64, 128)  17664       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 64, 64, 128)  512         separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 64, 64, 128)  0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 64, 64, 256)  0           concatenate_3[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 64, 64, 256)  68096       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 64, 64, 256)  1024        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 64, 64, 256)  68096       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 64, 64, 256)  1024        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64, 64, 512)  0           concatenate_4[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 64, 64, 512)  267264      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 64, 64, 512)  2048        separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 64, 64, 512)  267264      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 64, 64, 512)  2048        separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 64, 64, 1024) 0           concatenate_5[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 128)  131200      concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 64, 64, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 64, 128)  0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 64, 64, 192)  0           activation_7[0][0]               \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 64, 64, 128)  26432       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 64, 64, 128)  512         separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 64, 64, 128)  0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 64, 64, 128)  17664       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 64, 64, 128)  512         separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 64, 64, 128)  0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 64, 64, 320)  0           concatenate_7[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 64, 64, 256)  85056       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 64, 64, 256)  1024        separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 64, 64, 256)  68096       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 64, 64, 256)  1024        separable_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 64, 64, 576)  0           concatenate_8[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 64, 64, 512)  300608      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 64, 64, 512)  2048        separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 64, 64, 512)  267264      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 64, 64, 512)  2048        separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 64, 64, 1088) 0           concatenate_9[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 64, 64, 1024) 1124928     concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 64, 64, 1024) 4096        separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 64, 64, 1024) 0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 64, 64, 1024) 1058816     activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 64, 64, 1024) 4096        separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 64, 64, 1024) 0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 64, 64, 2112) 0           concatenate_10[0][0]             \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 256)  540928      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 64, 64, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 64, 64, 448)  0           activation_7[0][0]               \n",
            "                                                                 activation_16[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 64, 64, 256)  118976      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 64, 64, 256)  1024        separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 64, 64, 256)  68096       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 64, 64, 256)  1024        separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 64, 64, 704)  0           concatenate_12[0][0]             \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 64, 64, 512)  367296      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 64, 64, 512)  2048        separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 64, 64, 512)  267264      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 64, 64, 512)  2048        separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 64, 64, 1216) 0           concatenate_13[0][0]             \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 64, 64, 512)  634048      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 64, 64, 512)  2048        separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 64, 64, 512)  267264      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 64, 64, 512)  2048        separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 64, 64, 512)  0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 64, 64, 1728) 0           concatenate_14[0][0]             \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 64, 64, 1024) 1786048     concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 64, 64, 1024) 4096        separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 64, 64, 1024) 0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 64, 64, 1024) 1058816     activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 64, 64, 1024) 4096        separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 64, 64, 1024) 0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 64, 64, 2752) 0           concatenate_15[0][0]             \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 256)  704768      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 64, 64, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 64, 64, 704)  0           activation_7[0][0]               \n",
            "                                                                 activation_16[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Maxpool (MaxPooling2D)          (None, 32, 32, 704)  0           concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 32, 32, 256)  186816      Maxpool[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 32, 32, 256)  1024        separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 32, 32, 256)  68096       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 32, 32, 256)  1024        separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 32, 32, 960)  0           Maxpool[0][0]                    \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 32, 32, 512)  500672      concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 32, 32, 512)  2048        separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 32, 32, 512)  267264      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 32, 32, 512)  2048        separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 32, 32, 1472) 0           concatenate_18[0][0]             \n",
            "                                                                 activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 200)  294600      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 32, 32, 200)  800         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 200)  0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 200)          0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 200)          0           global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 11,178,211\n",
            "Trainable params: 11,150,739\n",
            "Non-trainable params: 27,472\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrzPRRFmMw5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = tf.train.AdamOptimizer(0.001)\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjq-U8x5M4_Q",
        "colab_type": "code",
        "outputId": "73d26688-b3d0-47eb-eeb9-29eb63cb9678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.42.191.74:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 14709204905424248740)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12068932762043815323)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7941128398303201474)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4434097514750297218)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 18347907296588326655)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 10563043132392270339)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4808907752254341576)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13535578815761924512)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3947371411724688791)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13008749776643596293)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 18004103025218742125)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB-QJdHa-U8Z",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 71-80** (batchsize-100)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK_7nczFM9Z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_32x32_51_70.hdf5\")\n",
        "last_executed_epoch = 70\n",
        "nb_epoch = 80\n",
        "csv_logger = CSVLogger('Assignment4_V34_64x64_71_80.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzW5VOuGNHrp",
        "colab_type": "code",
        "outputId": "4b771e91-b03e-4b66-d6d5-100a4f219559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_71_80.hdf5\")\n",
        "!cp \"Assignment4_V34_64x64_71_80.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_71_80.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 71 - 80 : \n",
            "Epoch 71/80\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(12,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(12, 64, 64, 3), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(12, 200), dtype=tf.float32, name='activation_81_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 67.49458765983582 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            " 999/1000 [============================>.] - ETA: 1s - loss: 2.6700 - acc: 0.4350INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(12,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(12, 64, 64, 3), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(12, 200), dtype=tf.float32, name='activation_81_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 27.87162208557129 secs\n",
            "100/100 [==============================] - 54s 540ms/step - loss: 2.9474 - acc: 0.4139\n",
            "1000/1000 [==============================] - 1902s 2s/step - loss: 2.6701 - acc: 0.4350 - val_loss: 2.9474 - val_acc: 0.4139\n",
            "Epoch 72/80\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 2.8837 - acc: 0.4345\n",
            "1000/1000 [==============================] - 1706s 2s/step - loss: 2.5312 - acc: 0.4563 - val_loss: 2.8837 - val_acc: 0.4345\n",
            "Epoch 73/80\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 2.6598 - acc: 0.4697\n",
            "1000/1000 [==============================] - 1705s 2s/step - loss: 2.4701 - acc: 0.4672 - val_loss: 2.6598 - val_acc: 0.4697\n",
            "Epoch 74/80\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 3.0739 - acc: 0.4286\n",
            "1000/1000 [==============================] - 1706s 2s/step - loss: 2.4237 - acc: 0.4755 - val_loss: 3.0739 - val_acc: 0.4286\n",
            "Epoch 75/80\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 2.6961 - acc: 0.4575\n",
            "1000/1000 [==============================] - 1707s 2s/step - loss: 2.3843 - acc: 0.4805 - val_loss: 2.6961 - val_acc: 0.4575\n",
            "Epoch 76/80\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 2.8494 - acc: 0.4581\n",
            "1000/1000 [==============================] - 1707s 2s/step - loss: 2.3458 - acc: 0.4886 - val_loss: 2.8494 - val_acc: 0.4581\n",
            "Epoch 77/80\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 2.9235 - acc: 0.4383\n",
            "1000/1000 [==============================] - 1706s 2s/step - loss: 2.3093 - acc: 0.4975 - val_loss: 2.9235 - val_acc: 0.4383\n",
            "Epoch 78/80\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 2.8251 - acc: 0.4594\n",
            "1000/1000 [==============================] - 1706s 2s/step - loss: 2.2808 - acc: 0.5011 - val_loss: 2.8251 - val_acc: 0.4594\n",
            "Epoch 79/80\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 2.7636 - acc: 0.4675\n",
            "1000/1000 [==============================] - 1703s 2s/step - loss: 2.2458 - acc: 0.5079 - val_loss: 2.7636 - val_acc: 0.4675\n",
            "Epoch 80/80\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 2.7010 - acc: 0.4692\n",
            "1000/1000 [==============================] - 1707s 2s/step - loss: 2.2197 - acc: 0.5124 - val_loss: 2.7010 - val_acc: 0.4692\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiVBT_1U_gzl",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 81-90** (batchsize-128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGxDMF27_uIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_71_80.hdf5\")\n",
        "last_executed_epoch = 80\n",
        "nb_epoch = 90\n",
        "csv_logger = CSVLogger('Assignment4_V34_64x64_81_90.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoGegq5F_yX1",
        "colab_type": "code",
        "outputId": "3a250cd9-8fff-4ca0-ffc4-b30d6c4c1f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_81_90.hdf5\")\n",
        "!cp \"Assignment4_V34_64x64_81_90.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_81_90.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 81 - 90 : \n",
            "Epoch 81/90\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 53.63751268386841 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "154/782 [====>.........................] - ETA: 26:03 - loss: 2.0246 - acc: 0.5502INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 54.308671712875366 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 2.0365 - acc: 0.5467INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 35.74834871292114 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.5499 - acc: 0.4942INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 35.69256234169006 secs\n",
            "79/79 [==============================] - 100s 1s/step - loss: 2.5430 - acc: 0.4943\n",
            "782/782 [==============================] - 1619s 2s/step - loss: 2.0362 - acc: 0.5468 - val_loss: 2.5430 - val_acc: 0.4943\n",
            "Epoch 82/90\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.6856 - acc: 0.4898\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.9983 - acc: 0.5542 - val_loss: 2.6856 - val_acc: 0.4898\n",
            "Epoch 83/90\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.4592 - acc: 0.5087\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.9756 - acc: 0.5598 - val_loss: 2.4592 - val_acc: 0.5087\n",
            "Epoch 84/90\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.5492 - acc: 0.5022\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.9576 - acc: 0.5623 - val_loss: 2.5492 - val_acc: 0.5022\n",
            "Epoch 85/90\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.6910 - acc: 0.4861\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.9285 - acc: 0.5706 - val_loss: 2.6910 - val_acc: 0.4861\n",
            "Epoch 86/90\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.8009 - acc: 0.4840\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.9175 - acc: 0.5714 - val_loss: 2.8009 - val_acc: 0.4840\n",
            "Epoch 87/90\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.3850 - acc: 0.5255\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.8900 - acc: 0.5780 - val_loss: 2.3850 - val_acc: 0.5255\n",
            "Epoch 88/90\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.6011 - acc: 0.4971\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.8683 - acc: 0.5813 - val_loss: 2.6011 - val_acc: 0.4971\n",
            "Epoch 89/90\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.5348 - acc: 0.5173\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.8504 - acc: 0.5851 - val_loss: 2.5348 - val_acc: 0.5173\n",
            "Epoch 90/90\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.5452 - acc: 0.5103\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.8354 - acc: 0.5867 - val_loss: 2.5452 - val_acc: 0.5103\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFEW2hlbDWmP",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 91-100** (batchsize-128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KW92cJGDW76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_81_90.hdf5\")\n",
        "last_executed_epoch = 90\n",
        "nb_epoch = 100\n",
        "csv_logger = CSVLogger('Assignment4_V34_64x64_91_100.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSgnF1oiDXHV",
        "colab_type": "code",
        "outputId": "fe64c699-2161-4b67-bcd9-4804346a0b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_91_100.hdf5\")\n",
        "!cp \"Assignment4_V34_64x64_91_100.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_91_100.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 91 - 100 : \n",
            "Epoch 91/100\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 66.30171728134155 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "764/782 [============================>.] - ETA: 33s - loss: 1.8136 - acc: 0.5925INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 49.55241656303406 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.8151 - acc: 0.5922INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 31.218905448913574 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.6580 - acc: 0.5074INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.79714608192444 secs\n",
            "79/79 [==============================] - 90s 1s/step - loss: 2.6410 - acc: 0.5077\n",
            "782/782 [==============================] - 1621s 2s/step - loss: 1.8151 - acc: 0.5922 - val_loss: 2.6410 - val_acc: 0.5077\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.6150 - acc: 0.5011\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.7942 - acc: 0.5965 - val_loss: 2.6150 - val_acc: 0.5011\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.6596 - acc: 0.5074\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.7761 - acc: 0.6019 - val_loss: 2.6596 - val_acc: 0.5074\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.5447 - acc: 0.5201\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.7624 - acc: 0.6044 - val_loss: 2.5447 - val_acc: 0.5201\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.4997 - acc: 0.5219\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 1.7497 - acc: 0.6078 - val_loss: 2.4997 - val_acc: 0.5219\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.7138 - acc: 0.4932\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.7352 - acc: 0.6098 - val_loss: 2.7138 - val_acc: 0.4932\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.4906 - acc: 0.5237\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.7169 - acc: 0.6140 - val_loss: 2.4906 - val_acc: 0.5237\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.6804 - acc: 0.5105\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.6988 - acc: 0.6170 - val_loss: 2.6804 - val_acc: 0.5105\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.6450 - acc: 0.5084\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.6913 - acc: 0.6190 - val_loss: 2.6450 - val_acc: 0.5084\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3723 - acc: 0.5493\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.6714 - acc: 0.6242 - val_loss: 2.3723 - val_acc: 0.5493\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsUT6mZG-LHQ",
        "colab_type": "text"
      },
      "source": [
        "# Additional Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtVwJn046GRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "\n",
        "#aug1 = iaa.GaussianBlur(sigma=(0, 2.0))\n",
        "#aug2 = iaa.AdditiveGaussianNoise(scale=0.20 * 255)\n",
        "\n",
        "#aug3 = iaa.ChannelShuffle(p=1.0) # multiple if better for colour adjustments\n",
        "#aug4 = iaa.AddToHueAndSaturation((-50,50))\n",
        "#aug5 = iaa.GammaContrast((0.5,1.75),per_channel=True)\n",
        "#aug6 = PadToFixedSize(height'=height+32',width'=width+32', position='center')\n",
        "#aug7 = iaa.CoarseDropout(p=0.2, size_percent=0.02)\n",
        "#aug = iaa.Fliplr(0.5)\n",
        "#aug = iaa.Superpixels(p_replace=0.5, n_segments=64)\n",
        "#aug = iaa.Grayscale(alpha=(0.0, 1.0)) # Multiple is better for colour\n",
        "#aug = iaa.Add((-40, 40), per_channel=0.5) # Multiply is better than add for diff colours\n",
        "#aug = iaa.Multiply((0.5, 1.5), per_channel=0.5) # multiple colours\n",
        "#aug = iaa.Affine(scale=(0.5, 1.5)) # zoom\n",
        "#aug = iaa.Affine(rotate=(-45, 45)) # rotate\n",
        "#aug = iaa.Noop() # No operation\n",
        "\n",
        "# Below are 5 augmentation techniques used\n",
        "custom_aug = iaa.Sequential([\n",
        "      iaa.Fliplr(0.5),\n",
        "      iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
        "      iaa.Affine(scale=(0.25, 2.0)),\n",
        "      iaa.Sometimes(0.7,iaa.CoarseDropout(p=0.2, size_percent=0.02),iaa.Affine(rotate=(-45, 45)))\n",
        "      ], random_order=False)\n",
        "\n",
        "\n",
        "def additional_augmenation(image):\n",
        "    #image = aug1.augment_image(image)\n",
        "    #image = aug2.augment_image(image)\n",
        "    image = custom_aug.augment_image(image)\n",
        "    #image = aug4.augment_image(image)\n",
        "    #image = aug7.augment_image(image)\n",
        "    #image = skimage.exposure.rescale_intensity(aug5.augment_image(image),in_range=(0, 255))\n",
        "    return image\n",
        "  \n",
        "train_datagen = ImageDataGenerator(\n",
        "       #featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "      # samplewise_center=False,  # set each sample mean to 0\n",
        "      #  featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "      #  samplewise_std_normalization=False,  # divide each input by its std\n",
        "      #  zca_whitening=False,  # apply ZCA whitening\n",
        "      #  rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "      #  width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "       # height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "       # horizontal_flip=True,  # randomly flip images\n",
        "       # zoom_range=[0.5, 1.5], #zoom\n",
        "      #  vertical_flip=False, # randomly flip images\n",
        "        rescale= 1./255,\n",
        "        preprocessing_function=additional_augmenation)  \n",
        "\n",
        "\n",
        "\n",
        "val_data = pd.read_csv(\"./tiny-imagenet-200/val/val_annotations.txt\", sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "\n",
        "valid_datagen=ImageDataGenerator(rescale= 1./255)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG1dsfXd-QZR",
        "colab_type": "text"
      },
      "source": [
        "**Setup required after addition augmentation changes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fBXt1PO-aXc",
        "colab_type": "code",
        "outputId": "9b883fbf-8e7a-4b33-eda9-73a5b8ded873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_generator_64 = train_datagen.flow_from_directory(\n",
        "    directory=\"./tiny-imagenet-200/train/\",\n",
        "    target_size=(64, 64),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=128,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "   # save_to_dir=\"/content/gdrive/My Drive/Assignment_4/Augmented_Images/Additional\",\n",
        "    seed=1\n",
        ")\n",
        "valid_generator_64=valid_datagen.flow_from_dataframe(dataframe=val_data, directory=\"./tiny-imagenet-200/val/images/\", x_col=\"File\", y_col=\"Class\", class_mode=\"categorical\",validate_filenames=False, shuffle=True, target_size=(64,64), batch_size=128,seed=1)\n",
        "\n",
        "STEP_SIZE_TRAIN_64 = train_generator_64.n//train_generator_64.batch_size\n",
        "STEP_SIZE_VALID_64 = valid_generator_64.n//valid_generator_64.batch_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuGGAl3I-teu",
        "colab_type": "code",
        "outputId": "8018728f-017c-4048-a288-d7d2ba4e9a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "# The imagenet images are RGB.\n",
        "nb_classes = 200\n",
        "img_channels = 3\n",
        "\n",
        "model = ResnetBuilder.build_custom_resnet((img_channels, img_rows, img_cols), nb_classes)\n",
        "#model.summary() #Model summary is same as before so not printing it here agian.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEbreWT6-9qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = tf.train.AdamOptimizer(0.001)\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kanixjO3--Tn",
        "colab_type": "code",
        "outputId": "fa8533e4-8bd7-495e-d64f-a98495f2816e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.4.213.10:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4313406809111492259)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4506753524439952341)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17784538767339841784)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 390743458509973771)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4248580409610210351)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9465965433712178690)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10770749135754516838)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1462807666267413378)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9875596676998249099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16362100060385948876)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 6977783744482734265)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H5I5vHw_TcM",
        "colab_type": "text"
      },
      "source": [
        "# Model Training on 64*64 images - with Additional Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-NYTb84jNQP",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 100-110** (batchsize-128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCT2zirhjN_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V34_64x64_91_100.hdf5\")\n",
        "last_executed_epoch = 100\n",
        "nb_epoch = 110\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_101_110.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuvozFw-jOVE",
        "colab_type": "code",
        "outputId": "a83f61d9-97bd-4ba1-ac85-b3e401f1c971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_101_110.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_101_110.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_101_110.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 101 - 110 : \n",
            "Epoch 101/110\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 65.42139983177185 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "454/782 [================>.............] - ETA: 10:57 - loss: 2.5996 - acc: 0.4344INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 50.235307931900024 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 2.5454 - acc: 0.4440INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.73282027244568 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.8285 - acc: 0.4802INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.8545503616333 secs\n",
            "79/79 [==============================] - 90s 1s/step - loss: 2.8260 - acc: 0.4802\n",
            "782/782 [==============================] - 1623s 2s/step - loss: 2.5454 - acc: 0.4441 - val_loss: 2.8260 - val_acc: 0.4802\n",
            "Epoch 102/110\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.6306 - acc: 0.5121\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 2.3681 - acc: 0.4763 - val_loss: 2.6306 - val_acc: 0.5121\n",
            "Epoch 103/110\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.3930 - acc: 0.5353\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 2.3116 - acc: 0.4873 - val_loss: 2.3930 - val_acc: 0.5353\n",
            "Epoch 104/110\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.5830 - acc: 0.5175\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 2.2642 - acc: 0.4974 - val_loss: 2.5830 - val_acc: 0.5175\n",
            "Epoch 105/110\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.6554 - acc: 0.5029\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 2.2346 - acc: 0.5033 - val_loss: 2.6554 - val_acc: 0.5029\n",
            "Epoch 106/110\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3856 - acc: 0.5539\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 2.2092 - acc: 0.5087 - val_loss: 2.3856 - val_acc: 0.5539\n",
            "Epoch 107/110\n",
            "79/79 [==============================] - 19s 242ms/step - loss: 2.6944 - acc: 0.5110\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 2.1822 - acc: 0.5130 - val_loss: 2.6944 - val_acc: 0.5110\n",
            "Epoch 108/110\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.5600 - acc: 0.5280\n",
            "782/782 [==============================] - 1325s 2s/step - loss: 2.1543 - acc: 0.5195 - val_loss: 2.5600 - val_acc: 0.5280\n",
            "Epoch 109/110\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.3998 - acc: 0.5415\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 2.1401 - acc: 0.5229 - val_loss: 2.3998 - val_acc: 0.5415\n",
            "Epoch 110/110\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.4299 - acc: 0.5354\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 2.1205 - acc: 0.5274 - val_loss: 2.4299 - val_acc: 0.5354\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIMKr6DVZ9b0",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 111-120** (batchsize-128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKbFBNRTZ-VH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_101_110.hdf5\")\n",
        "last_executed_epoch = 110\n",
        "nb_epoch = 120\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_111_120.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGy7eEyUZ-rf",
        "colab_type": "code",
        "outputId": "0d14bba7-8bec-4f94-ff97-588c7cf9aa4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1173
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_111_120.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_111_120.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_111_120.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 111 - 120 : \n",
            "Epoch 111/120\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.4985 - acc: 0.5245\n",
            "782/782 [==============================] - 1353s 2s/step - loss: 2.1091 - acc: 0.5288 - val_loss: 2.4985 - val_acc: 0.5245\n",
            "Epoch 112/120\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.5750 - acc: 0.5169\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 2.0838 - acc: 0.5335 - val_loss: 2.5750 - val_acc: 0.5169\n",
            "Epoch 113/120\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.3251 - acc: 0.5608\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 2.0672 - acc: 0.5392 - val_loss: 2.3251 - val_acc: 0.5608\n",
            "Epoch 114/120\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.4893 - acc: 0.5344\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 2.0612 - acc: 0.5393 - val_loss: 2.4893 - val_acc: 0.5344\n",
            "Epoch 115/120\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3674 - acc: 0.5456\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 2.0432 - acc: 0.5419 - val_loss: 2.3674 - val_acc: 0.5456\n",
            "Epoch 116/120\n",
            "427/782 [===============>..............] - ETA: 9:54 - loss: 2.0135 - acc: 0.5495Training on 64*64 images: Epochs 111 - 120 : \n",
            "Epoch 111/120\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.4985 - acc: 0.5245\n",
            "782/782 [==============================] - 1353s 2s/step - loss: 2.1091 - acc: 0.5288 - val_loss: 2.4985 - val_acc: 0.5245\n",
            "Epoch 112/120\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.5750 - acc: 0.5169\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 2.0838 - acc: 0.5335 - val_loss: 2.5750 - val_acc: 0.5169\n",
            "Epoch 113/120\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.3251 - acc: 0.5608\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 2.0672 - acc: 0.5392 - val_loss: 2.3251 - val_acc: 0.5608\n",
            "Epoch 114/120\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.4893 - acc: 0.5344\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 2.0612 - acc: 0.5393 - val_loss: 2.4893 - val_acc: 0.5344\n",
            "Epoch 115/120\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3674 - acc: 0.5456\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 2.0432 - acc: 0.5419 - val_loss: 2.3674 - val_acc: 0.5456\n",
            "Epoch 116/120\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.5122 - acc: 0.5202\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.5122 - acc: 0.5202\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 2.0258 - acc: 0.5468 - val_loss: 2.5122 - val_acc: 0.5202\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 2.0258 - acc: 0.5468 - val_loss: 2.5122 - val_acc: 0.5202\n",
            "Epoch 117/120\n",
            "Epoch 117/120\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.5395 - acc: 0.5226\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.5395 - acc: 0.5226\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 2.0119 - acc: 0.5490 - val_loss: 2.5395 - val_acc: 0.5226\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 2.0119 - acc: 0.5490 - val_loss: 2.5395 - val_acc: 0.5226\n",
            "Epoch 118/120\n",
            "Epoch 118/120\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3643 - acc: 0.5475\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3643 - acc: 0.5475\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 2.0006 - acc: 0.5510 - val_loss: 2.3643 - val_acc: 0.5475\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 2.0006 - acc: 0.5510 - val_loss: 2.3643 - val_acc: 0.5475\n",
            "Epoch 119/120\n",
            "Epoch 119/120\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.5460 - acc: 0.5394\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.5460 - acc: 0.5394\n",
            "782/782 [==============================] - 1321s 2s/step - loss: 1.9926 - acc: 0.5533 - val_loss: 2.5460 - val_acc: 0.5394\n",
            "782/782 [==============================] - 1321s 2s/step - loss: 1.9926 - acc: 0.5533 - val_loss: 2.5460 - val_acc: 0.5394\n",
            "Epoch 120/120\n",
            "Epoch 120/120\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3079 - acc: 0.5624\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3079 - acc: 0.5624\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.9727 - acc: 0.5576 - val_loss: 2.3079 - val_acc: 0.5624\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.9727 - acc: 0.5576 - val_loss: 2.3079 - val_acc: 0.5624\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKrSuBY2DPcV",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 121-130** (batchsize-128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU7kaiC8DQEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_111_120.hdf5\")\n",
        "last_executed_epoch = 120\n",
        "nb_epoch = 130\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_121_130.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYQl7Bv-DQbI",
        "colab_type": "code",
        "outputId": "0065a2db-874f-4614-9ccb-44bf22590322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_121_130.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_121_130.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_121_130.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 121 - 130 : \n",
            "Epoch 121/130\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 65.5228705406189 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "244/782 [========>.....................] - ETA: 20:41 - loss: 1.9468 - acc: 0.5657INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 50.29424571990967 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.9618 - acc: 0.5611INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.429584741592407 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.3468 - acc: 0.5642INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.5698504447937 secs\n",
            "79/79 [==============================] - 89s 1s/step - loss: 2.3378 - acc: 0.5643\n",
            "782/782 [==============================] - 1628s 2s/step - loss: 1.9620 - acc: 0.5611 - val_loss: 2.3378 - val_acc: 0.5643\n",
            "Epoch 122/130\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.3491 - acc: 0.5525\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.9490 - acc: 0.5603 - val_loss: 2.3491 - val_acc: 0.5525\n",
            "Epoch 123/130\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.2811 - acc: 0.5626\n",
            "782/782 [==============================] - 1335s 2s/step - loss: 1.9426 - acc: 0.5641 - val_loss: 2.2811 - val_acc: 0.5626\n",
            "Epoch 124/130\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.3559 - acc: 0.5463\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.9194 - acc: 0.5710 - val_loss: 2.3559 - val_acc: 0.5463\n",
            "Epoch 125/130\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.2888 - acc: 0.5604\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.9148 - acc: 0.5710 - val_loss: 2.2888 - val_acc: 0.5604\n",
            "Epoch 126/130\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.3681 - acc: 0.5572\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.9084 - acc: 0.5704 - val_loss: 2.3681 - val_acc: 0.5572\n",
            "Epoch 127/130\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.4561 - acc: 0.5484\n",
            "782/782 [==============================] - 1332s 2s/step - loss: 1.8972 - acc: 0.5730 - val_loss: 2.4561 - val_acc: 0.5484\n",
            "Epoch 128/130\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.5856 - acc: 0.5309\n",
            "782/782 [==============================] - 1333s 2s/step - loss: 1.8782 - acc: 0.5779 - val_loss: 2.5856 - val_acc: 0.5309\n",
            "Epoch 129/130\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.3956 - acc: 0.5456\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.8753 - acc: 0.5774 - val_loss: 2.3956 - val_acc: 0.5456\n",
            "Epoch 130/130\n",
            "79/79 [==============================] - 19s 242ms/step - loss: 2.3095 - acc: 0.5591\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 1.8686 - acc: 0.5784 - val_loss: 2.3095 - val_acc: 0.5591\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMT0wtT9Ei7z",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 131-140** (batchsize-128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztz4t1d6Ejhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_121_130.hdf5\")\n",
        "last_executed_epoch = 130\n",
        "nb_epoch = 140\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_131_140.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWXBi8XbEkBu",
        "colab_type": "code",
        "outputId": "0897d715-2d70-47e2-8ec2-7633ae59ba53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_131_140.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_131_140.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_131_140.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 131 - 140 : \n",
            "Epoch 131/140\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 65.72786903381348 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "389/782 [=============>................] - ETA: 13:26 - loss: 1.8487 - acc: 0.5843INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 49.21705484390259 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.8625 - acc: 0.5819INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 31.57836413383484 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.5930 - acc: 0.5406INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 32.24924898147583 secs\n",
            "79/79 [==============================] - 91s 1s/step - loss: 2.5775 - acc: 0.5405\n",
            "782/782 [==============================] - 1615s 2s/step - loss: 1.8629 - acc: 0.5819 - val_loss: 2.5775 - val_acc: 0.5405\n",
            "Epoch 132/140\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.2787 - acc: 0.5613\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.8371 - acc: 0.5860 - val_loss: 2.2787 - val_acc: 0.5613\n",
            "Epoch 133/140\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.4663 - acc: 0.5518\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.8359 - acc: 0.5862 - val_loss: 2.4663 - val_acc: 0.5518\n",
            "Epoch 134/140\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3659 - acc: 0.5524\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.8251 - acc: 0.5894 - val_loss: 2.3659 - val_acc: 0.5524\n",
            "Epoch 135/140\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3278 - acc: 0.5632\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.8122 - acc: 0.5918 - val_loss: 2.3278 - val_acc: 0.5632\n",
            "Epoch 136/140\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.3764 - acc: 0.5663\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.8118 - acc: 0.5921 - val_loss: 2.3764 - val_acc: 0.5663\n",
            "Epoch 137/140\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.3529 - acc: 0.5614\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.7953 - acc: 0.5954 - val_loss: 2.3529 - val_acc: 0.5614\n",
            "Epoch 138/140\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 2.2842 - acc: 0.5650\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 1.7789 - acc: 0.5991 - val_loss: 2.2842 - val_acc: 0.5650\n",
            "Epoch 139/140\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.1743 - acc: 0.5771\n",
            "782/782 [==============================] - 1325s 2s/step - loss: 1.7798 - acc: 0.5981 - val_loss: 2.1743 - val_acc: 0.5771\n",
            "Epoch 140/140\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.2345 - acc: 0.5767\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.7715 - acc: 0.6008 - val_loss: 2.2345 - val_acc: 0.5767\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt7me4hF9T99",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 141-150** (batchsize-128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUt0UHxc9UZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_131_140.hdf5\")\n",
        "last_executed_epoch = 140\n",
        "nb_epoch = 150\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_141_150.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybrg3CJH9UsZ",
        "colab_type": "code",
        "outputId": "e2c1950b-6c20-41c6-c96b-ab2239149a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_141_150.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_141_150.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_141_150.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 141 - 150 : \n",
            "Epoch 141/150\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.4050 - acc: 0.5507\n",
            "782/782 [==============================] - 1348s 2s/step - loss: 1.7723 - acc: 0.6007 - val_loss: 2.4050 - val_acc: 0.5507\n",
            "Epoch 142/150\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.2962 - acc: 0.5743\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.7590 - acc: 0.6032 - val_loss: 2.2962 - val_acc: 0.5743\n",
            "Epoch 143/150\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.4032 - acc: 0.5457\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.7483 - acc: 0.6049 - val_loss: 2.4032 - val_acc: 0.5457\n",
            "Epoch 144/150\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.2869 - acc: 0.5624\n",
            "782/782 [==============================] - 1321s 2s/step - loss: 1.7449 - acc: 0.6042 - val_loss: 2.2869 - val_acc: 0.5624\n",
            "Epoch 145/150\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 2.3589 - acc: 0.5494\n",
            "782/782 [==============================] - 1320s 2s/step - loss: 1.7350 - acc: 0.6075 - val_loss: 2.3589 - val_acc: 0.5494\n",
            "Epoch 146/150\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.4209 - acc: 0.5544\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 1.7265 - acc: 0.6096 - val_loss: 2.4209 - val_acc: 0.5544\n",
            "Epoch 147/150\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.2763 - acc: 0.5810\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.7150 - acc: 0.6138 - val_loss: 2.2763 - val_acc: 0.5810\n",
            "Epoch 148/150\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.3717 - acc: 0.5634\n",
            "782/782 [==============================] - 1320s 2s/step - loss: 1.7156 - acc: 0.6112 - val_loss: 2.3717 - val_acc: 0.5634\n",
            "Epoch 149/150\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3113 - acc: 0.5787\n",
            "782/782 [==============================] - 1320s 2s/step - loss: 1.7039 - acc: 0.6148 - val_loss: 2.3113 - val_acc: 0.5787\n",
            "Epoch 150/150\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3936 - acc: 0.5661\n",
            "782/782 [==============================] - 1320s 2s/step - loss: 1.6886 - acc: 0.6181 - val_loss: 2.3936 - val_acc: 0.5661\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7AiT8h96TfQ",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 151-160** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOO-VJu56UHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_141_150.hdf5\")\n",
        "last_executed_epoch = 150\n",
        "nb_epoch = 160\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_151_160.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-a75bDx6UjD",
        "colab_type": "code",
        "outputId": "6029f615-3f14-47fb-a604-9f5cb8ba899e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_151_160.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_151_160.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_151_160.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 151 - 160 : \n",
            "Epoch 151/160\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 64.70670461654663 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "627/782 [=======================>......] - ETA: 4:56 - loss: 1.6882 - acc: 0.6191INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 49.610307931900024 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.6965 - acc: 0.6170INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.1308650970459 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.2399 - acc: 0.5780INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.791320323944092 secs\n",
            "79/79 [==============================] - 89s 1s/step - loss: 2.2372 - acc: 0.5779\n",
            "782/782 [==============================] - 1620s 2s/step - loss: 1.6966 - acc: 0.6169 - val_loss: 2.2372 - val_acc: 0.5779\n",
            "Epoch 152/160\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.2563 - acc: 0.5713\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.6755 - acc: 0.6208 - val_loss: 2.2563 - val_acc: 0.5713\n",
            "Epoch 153/160\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.2975 - acc: 0.5780\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.6723 - acc: 0.6219 - val_loss: 2.2975 - val_acc: 0.5780\n",
            "Epoch 154/160\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.5293 - acc: 0.5396\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.6644 - acc: 0.6226 - val_loss: 2.5293 - val_acc: 0.5396\n",
            "Epoch 155/160\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3374 - acc: 0.5635\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.6506 - acc: 0.6270 - val_loss: 2.3374 - val_acc: 0.5635\n",
            "Epoch 156/160\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.3705 - acc: 0.5651\n",
            "782/782 [==============================] - 1325s 2s/step - loss: 1.6530 - acc: 0.6253 - val_loss: 2.3705 - val_acc: 0.5651\n",
            "Epoch 157/160\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.3865 - acc: 0.5574\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.6436 - acc: 0.6267 - val_loss: 2.3865 - val_acc: 0.5574\n",
            "Epoch 158/160\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3733 - acc: 0.5538\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.6320 - acc: 0.6301 - val_loss: 2.3733 - val_acc: 0.5538\n",
            "Epoch 159/160\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.2982 - acc: 0.5798\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.6275 - acc: 0.6311 - val_loss: 2.2982 - val_acc: 0.5798\n",
            "Epoch 160/160\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.2851 - acc: 0.5823\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.6198 - acc: 0.6329 - val_loss: 2.2851 - val_acc: 0.5823\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBl0NQK7q7H3",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 161-170** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9tXUx8gq7ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_151_160.hdf5\")\n",
        "last_executed_epoch = 160\n",
        "nb_epoch = 170\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_161_170.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NCvljVqq74Y",
        "colab_type": "code",
        "outputId": "b6777f40-9091-43ff-9a5d-e4febdd79e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_161_170.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_161_170.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_161_170.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 161 - 170 : \n",
            "Epoch 161/170\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 65.15072226524353 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "666/782 [========================>.....] - ETA: 3:39 - loss: 1.6115 - acc: 0.6362INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 49.99198079109192 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.6189 - acc: 0.6350INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.899599075317383 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.4206 - acc: 0.5617INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.68465304374695 secs\n",
            "79/79 [==============================] - 88s 1s/step - loss: 2.4124 - acc: 0.5617\n",
            "782/782 [==============================] - 1616s 2s/step - loss: 1.6187 - acc: 0.6350 - val_loss: 2.4124 - val_acc: 0.5617\n",
            "Epoch 162/170\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.3709 - acc: 0.5742\n",
            "782/782 [==============================] - 1325s 2s/step - loss: 1.6049 - acc: 0.6374 - val_loss: 2.3709 - val_acc: 0.5742\n",
            "Epoch 163/170\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.2877 - acc: 0.5829\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.6010 - acc: 0.6368 - val_loss: 2.2877 - val_acc: 0.5829\n",
            "Epoch 164/170\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.2957 - acc: 0.5745\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.5948 - acc: 0.6397 - val_loss: 2.2957 - val_acc: 0.5745\n",
            "Epoch 165/170\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.3716 - acc: 0.5631\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.5864 - acc: 0.6394 - val_loss: 2.3716 - val_acc: 0.5631\n",
            "Epoch 166/170\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.2792 - acc: 0.5774\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.5837 - acc: 0.6416 - val_loss: 2.2792 - val_acc: 0.5774\n",
            "Epoch 167/170\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.2744 - acc: 0.5833\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.5799 - acc: 0.6409 - val_loss: 2.2744 - val_acc: 0.5833\n",
            "Epoch 168/170\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.2515 - acc: 0.5890\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.5654 - acc: 0.6452 - val_loss: 2.2515 - val_acc: 0.5890\n",
            "Epoch 169/170\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3412 - acc: 0.5817\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.5565 - acc: 0.6464 - val_loss: 2.3412 - val_acc: 0.5817\n",
            "Epoch 170/170\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.2932 - acc: 0.5667\n",
            "782/782 [==============================] - 1325s 2s/step - loss: 1.5529 - acc: 0.6479 - val_loss: 2.2932 - val_acc: 0.5667\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IDltFj7rr82",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 171-180** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z807IZ_ErsYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_161_170.hdf5\")\n",
        "last_executed_epoch = 170\n",
        "nb_epoch = 180\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_171_180.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1RI6EpxrshS",
        "colab_type": "code",
        "outputId": "0a47a804-6f2e-49a1-915d-cc7cd2352a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_171_180.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_171_180.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_171_180.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 171 - 180 : \n",
            "Epoch 171/180\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 67.9875226020813 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "361/782 [============>.................] - ETA: 14:40 - loss: 1.5433 - acc: 0.6506INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 50.101921796798706 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.5596 - acc: 0.6472INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.870850086212158 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.3893 - acc: 0.5686INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 32.85942625999451 secs\n",
            "79/79 [==============================] - 91s 1s/step - loss: 2.3787 - acc: 0.5687\n",
            "782/782 [==============================] - 1624s 2s/step - loss: 1.5598 - acc: 0.6472 - val_loss: 2.3787 - val_acc: 0.5687\n",
            "Epoch 172/180\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.4068 - acc: 0.5774\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.5423 - acc: 0.6494 - val_loss: 2.4068 - val_acc: 0.5774\n",
            "Epoch 173/180\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3030 - acc: 0.5794\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.5330 - acc: 0.6507 - val_loss: 2.3030 - val_acc: 0.5794\n",
            "Epoch 174/180\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.3598 - acc: 0.5818\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.5327 - acc: 0.6516 - val_loss: 2.3598 - val_acc: 0.5818\n",
            "Epoch 175/180\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3081 - acc: 0.5814\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.5206 - acc: 0.6559 - val_loss: 2.3081 - val_acc: 0.5814\n",
            "Epoch 176/180\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.4695 - acc: 0.5575\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.5188 - acc: 0.6568 - val_loss: 2.4695 - val_acc: 0.5575\n",
            "Epoch 177/180\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3565 - acc: 0.5774\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.5139 - acc: 0.6554 - val_loss: 2.3565 - val_acc: 0.5774\n",
            "Epoch 178/180\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3130 - acc: 0.5800\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.4994 - acc: 0.6598 - val_loss: 2.3130 - val_acc: 0.5800\n",
            "Epoch 179/180\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.2978 - acc: 0.5889\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.4916 - acc: 0.6601 - val_loss: 2.2978 - val_acc: 0.5889\n",
            "Epoch 180/180\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3363 - acc: 0.5749\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.4873 - acc: 0.6627 - val_loss: 2.3363 - val_acc: 0.5749\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "cp: cannot stat 'Assignment4_V36_64x64_161_170.csv': No such file or directory\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3jBKRCOWGhA",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 181-190** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGJZG5azWGuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_171_180.hdf5\")\n",
        "last_executed_epoch = 180\n",
        "nb_epoch = 190\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_181_190.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfp12VyRWGz4",
        "colab_type": "code",
        "outputId": "636c91f1-8ad1-4bc1-aaf6-386d8f4937c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_181_190.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_181_190.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_181_190.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 181 - 190 : \n",
            "Epoch 181/190\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 66.21472811698914 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "213/782 [=======>......................] - ETA: 22:32 - loss: 1.4617 - acc: 0.6711INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 50.89191675186157 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.4965 - acc: 0.6616INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.297454118728638 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.3299 - acc: 0.5854INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 32.09181618690491 secs\n",
            "79/79 [==============================] - 90s 1s/step - loss: 2.3380 - acc: 0.5853\n",
            "782/782 [==============================] - 1622s 2s/step - loss: 1.4966 - acc: 0.6615 - val_loss: 2.3380 - val_acc: 0.5853\n",
            "Epoch 182/190\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.1973 - acc: 0.5824\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.4825 - acc: 0.6630 - val_loss: 2.1973 - val_acc: 0.5824\n",
            "Epoch 183/190\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3895 - acc: 0.5715\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.4772 - acc: 0.6649 - val_loss: 2.3895 - val_acc: 0.5715\n",
            "Epoch 184/190\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.2925 - acc: 0.5742\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.4674 - acc: 0.6658 - val_loss: 2.2925 - val_acc: 0.5742\n",
            "Epoch 185/190\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.2831 - acc: 0.5789\n",
            "782/782 [==============================] - 1332s 2s/step - loss: 1.4625 - acc: 0.6685 - val_loss: 2.2831 - val_acc: 0.5789\n",
            "Epoch 186/190\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.4366 - acc: 0.5734\n",
            "782/782 [==============================] - 1333s 2s/step - loss: 1.4660 - acc: 0.6669 - val_loss: 2.4366 - val_acc: 0.5734\n",
            "Epoch 187/190\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.3526 - acc: 0.5763\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.4563 - acc: 0.6706 - val_loss: 2.3526 - val_acc: 0.5763\n",
            "Epoch 188/190\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.3333 - acc: 0.5782\n",
            "782/782 [==============================] - 1332s 2s/step - loss: 1.4480 - acc: 0.6718 - val_loss: 2.3333 - val_acc: 0.5782\n",
            "Epoch 189/190\n",
            "79/79 [==============================] - 19s 243ms/step - loss: 2.3817 - acc: 0.5826\n",
            "782/782 [==============================] - 1333s 2s/step - loss: 1.4422 - acc: 0.6716 - val_loss: 2.3817 - val_acc: 0.5826\n",
            "Epoch 190/190\n",
            "79/79 [==============================] - 19s 246ms/step - loss: 2.3217 - acc: 0.5814\n",
            "782/782 [==============================] - 1335s 2s/step - loss: 1.4344 - acc: 0.6750 - val_loss: 2.3217 - val_acc: 0.5814\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXjjRKfD-31O",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 191-200** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCB3lb5P-2ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_181_190.hdf5\")\n",
        "last_executed_epoch = 190\n",
        "nb_epoch = 200\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_191_200.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT2JIiKH-20t",
        "colab_type": "code",
        "outputId": "134fa0f6-7459-441d-dd8d-286258b78618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_191_200.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_191_200.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_191_200.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 191 - 200 : \n",
            "Epoch 191/200\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "79/79 [==============================] - 19s 243ms/step - loss: 2.3480 - acc: 0.5739\n",
            "782/782 [==============================] - 1361s 2s/step - loss: 1.4449 - acc: 0.6718 - val_loss: 2.3480 - val_acc: 0.5739\n",
            "Epoch 192/200\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.2154 - acc: 0.5901\n",
            "782/782 [==============================] - 1340s 2s/step - loss: 1.4395 - acc: 0.6728 - val_loss: 2.2154 - val_acc: 0.5901\n",
            "Epoch 193/200\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.2923 - acc: 0.5781\n",
            "782/782 [==============================] - 1340s 2s/step - loss: 1.4303 - acc: 0.6750 - val_loss: 2.2923 - val_acc: 0.5781\n",
            "Epoch 194/200\n",
            "79/79 [==============================] - 19s 245ms/step - loss: 2.4737 - acc: 0.5566\n",
            "782/782 [==============================] - 1340s 2s/step - loss: 1.4299 - acc: 0.6749 - val_loss: 2.4737 - val_acc: 0.5566\n",
            "Epoch 195/200\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.3731 - acc: 0.5747\n",
            "782/782 [==============================] - 1337s 2s/step - loss: 1.4253 - acc: 0.6777 - val_loss: 2.3731 - val_acc: 0.5747\n",
            "Epoch 196/200\n",
            "79/79 [==============================] - 19s 247ms/step - loss: 2.2725 - acc: 0.5830\n",
            "782/782 [==============================] - 1343s 2s/step - loss: 1.4108 - acc: 0.6791 - val_loss: 2.2725 - val_acc: 0.5830\n",
            "Epoch 197/200\n",
            "79/79 [==============================] - 19s 242ms/step - loss: 2.3063 - acc: 0.5794\n",
            "782/782 [==============================] - 1340s 2s/step - loss: 1.4073 - acc: 0.6810 - val_loss: 2.3063 - val_acc: 0.5794\n",
            "Epoch 198/200\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.2044 - acc: 0.5949\n",
            "782/782 [==============================] - 1340s 2s/step - loss: 1.4121 - acc: 0.6799 - val_loss: 2.2044 - val_acc: 0.5949\n",
            "Epoch 199/200\n",
            "79/79 [==============================] - 19s 244ms/step - loss: 2.2980 - acc: 0.5890\n",
            "782/782 [==============================] - 1335s 2s/step - loss: 1.4083 - acc: 0.6791 - val_loss: 2.2980 - val_acc: 0.5890\n",
            "Epoch 200/200\n",
            "79/79 [==============================] - 19s 244ms/step - loss: 2.3674 - acc: 0.5768\n",
            "782/782 [==============================] - 1337s 2s/step - loss: 1.3968 - acc: 0.6831 - val_loss: 2.3674 - val_acc: 0.5768\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLwMgSVVCtZM",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 201-210** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D53kz7EpCtqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_191_200.hdf5\")\n",
        "last_executed_epoch = 200\n",
        "nb_epoch = 210\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_201_210.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "438n7hCyCt0f",
        "colab_type": "code",
        "outputId": "42f03ebd-9957-4322-cbd9-52a6e929acd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_201_210.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_201_210.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_201_210.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 201 - 210 : \n",
            "Epoch 201/210\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 64.69607996940613 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "632/782 [=======================>......] - ETA: 4:46 - loss: 1.3880 - acc: 0.6832INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 50.49182844161987 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.3948 - acc: 0.6826INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 29.845507860183716 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.2544 - acc: 0.5927INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 30.739671230316162 secs\n",
            "79/79 [==============================] - 89s 1s/step - loss: 2.2595 - acc: 0.5925\n",
            "782/782 [==============================] - 1618s 2s/step - loss: 1.3951 - acc: 0.6825 - val_loss: 2.2595 - val_acc: 0.5925\n",
            "Epoch 202/210\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 2.3472 - acc: 0.5778\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.3830 - acc: 0.6853 - val_loss: 2.3472 - val_acc: 0.5778\n",
            "Epoch 203/210\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3766 - acc: 0.5689\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.3731 - acc: 0.6882 - val_loss: 2.3766 - val_acc: 0.5689\n",
            "Epoch 204/210\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3442 - acc: 0.5793\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 1.3680 - acc: 0.6883 - val_loss: 2.3442 - val_acc: 0.5793\n",
            "Epoch 205/210\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3330 - acc: 0.5878\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.3624 - acc: 0.6916 - val_loss: 2.3330 - val_acc: 0.5878\n",
            "Epoch 206/210\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3839 - acc: 0.5788\n",
            "782/782 [==============================] - 1326s 2s/step - loss: 1.3643 - acc: 0.6923 - val_loss: 2.3839 - val_acc: 0.5788\n",
            "Epoch 207/210\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3294 - acc: 0.5807\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.3606 - acc: 0.6905 - val_loss: 2.3294 - val_acc: 0.5807\n",
            "Epoch 208/210\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3347 - acc: 0.5885\n",
            "782/782 [==============================] - 1323s 2s/step - loss: 1.3572 - acc: 0.6910 - val_loss: 2.3347 - val_acc: 0.5885\n",
            "Epoch 209/210\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3974 - acc: 0.5590\n",
            "782/782 [==============================] - 1322s 2s/step - loss: 1.3434 - acc: 0.6948 - val_loss: 2.3974 - val_acc: 0.5590\n",
            "Epoch 210/210\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.4523 - acc: 0.5800\n",
            "782/782 [==============================] - 1324s 2s/step - loss: 1.3441 - acc: 0.6947 - val_loss: 2.4523 - val_acc: 0.5800\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHn2aVNq8wRd",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 211-220** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkmByI1L8wdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_201_210.hdf5\")\n",
        "last_executed_epoch = 210\n",
        "nb_epoch = 220\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_211_220.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ9xE5vs8wk3",
        "colab_type": "code",
        "outputId": "5a2c76a2-b281-475b-f882-e56f2c51dce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_211_220.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_211_220.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_211_220.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 211 - 220 : \n",
            "Epoch 211/220\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 66.36090874671936 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            " 29/782 [>.............................] - ETA: 1:27:19 - loss: 1.2552 - acc: 0.7198INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(4, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 49.52117729187012 secs\n",
            "781/782 [============================>.] - ETA: 1s - loss: 1.3410 - acc: 0.6955INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(16, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 29.56965184211731 secs\n",
            "78/79 [============================>.] - ETA: 0s - loss: 2.4839 - acc: 0.5755INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 64, 64, 3), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(2, 200), dtype=tf.float32, name='activation_40_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 31.825653791427612 secs\n",
            "79/79 [==============================] - 90s 1s/step - loss: 2.4904 - acc: 0.5754\n",
            "782/782 [==============================] - 1625s 2s/step - loss: 1.3413 - acc: 0.6954 - val_loss: 2.4904 - val_acc: 0.5754\n",
            "Epoch 212/220\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.5068 - acc: 0.5669\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 1.3376 - acc: 0.6952 - val_loss: 2.5068 - val_acc: 0.5669\n",
            "Epoch 213/220\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.4025 - acc: 0.5696\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.3257 - acc: 0.6993 - val_loss: 2.4025 - val_acc: 0.5696\n",
            "Epoch 214/220\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.4588 - acc: 0.5737\n",
            "782/782 [==============================] - 1328s 2s/step - loss: 1.3184 - acc: 0.7007 - val_loss: 2.4588 - val_acc: 0.5737\n",
            "Epoch 215/220\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.5338 - acc: 0.5579\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.3213 - acc: 0.6986 - val_loss: 2.5338 - val_acc: 0.5579\n",
            "Epoch 216/220\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.3649 - acc: 0.5830\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.3154 - acc: 0.7024 - val_loss: 2.3649 - val_acc: 0.5830\n",
            "Epoch 217/220\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3868 - acc: 0.5862\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.3093 - acc: 0.7035 - val_loss: 2.3868 - val_acc: 0.5862\n",
            "Epoch 218/220\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.3980 - acc: 0.5821\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.3021 - acc: 0.7049 - val_loss: 2.3980 - val_acc: 0.5821\n",
            "Epoch 219/220\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.3014 - acc: 0.5851\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.3014 - acc: 0.7045 - val_loss: 2.3014 - val_acc: 0.5851\n",
            "Epoch 220/220\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.5186 - acc: 0.5684\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 1.2928 - acc: 0.7054 - val_loss: 2.5186 - val_acc: 0.5684\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OZCcAIutXOo",
        "colab_type": "text"
      },
      "source": [
        "**Training with 64*64 epoch 221-230** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JThs7gAmtLUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_201_210.hdf5\")\n",
        "last_executed_epoch = 220\n",
        "nb_epoch = 230\n",
        "csv_logger = CSVLogger('Assignment4_V36_64x64_221_230.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_3Hv35PtGNM",
        "colab_type": "code",
        "outputId": "40a6f7c4-a337-4533-de29-4b9b2377c983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "print('Training on 64*64 images: Epochs ' + str(last_executed_epoch+1) + ' - ' + str(nb_epoch) + \" : \")\n",
        "    \n",
        "    \n",
        "model.fit_generator(generator=train_generator_64,\n",
        "                        steps_per_epoch=STEP_SIZE_TRAIN_64,\n",
        "                        validation_data=valid_generator_64,\n",
        "                        validation_steps=STEP_SIZE_VALID_64,\n",
        "                        epochs=nb_epoch,\n",
        "                        initial_epoch=last_executed_epoch,verbose=1,\n",
        "                        callbacks=[csv_logger])\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_221_230.hdf5\")\n",
        "!cp \"Assignment4_V36_64x64_221_230.csv\" \"/content/gdrive/My Drive/Assignment_4/Training_Backup/Assignment4_V36_64x64_221_230.csv\"\n",
        "print('-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 64*64 images: Epochs 221 - 230 : \n",
            "Epoch 221/230\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.5543 - acc: 0.5601\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.3072 - acc: 0.7033 - val_loss: 2.5543 - val_acc: 0.5601\n",
            "Epoch 222/230\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.4611 - acc: 0.5697\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.2955 - acc: 0.7041 - val_loss: 2.4611 - val_acc: 0.5697\n",
            "Epoch 223/230\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3083 - acc: 0.5946\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 1.2951 - acc: 0.7056 - val_loss: 2.3083 - val_acc: 0.5946\n",
            "Epoch 224/230\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.4643 - acc: 0.5825\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.2910 - acc: 0.7075 - val_loss: 2.4643 - val_acc: 0.5825\n",
            "Epoch 225/230\n",
            "79/79 [==============================] - 19s 245ms/step - loss: 2.3944 - acc: 0.5825\n",
            "782/782 [==============================] - 1329s 2s/step - loss: 1.2846 - acc: 0.7082 - val_loss: 2.3944 - val_acc: 0.5825\n",
            "Epoch 226/230\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3979 - acc: 0.5903\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 1.2761 - acc: 0.7106 - val_loss: 2.3979 - val_acc: 0.5903\n",
            "Epoch 227/230\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.4346 - acc: 0.5660\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.2778 - acc: 0.7104 - val_loss: 2.4346 - val_acc: 0.5660\n",
            "Epoch 228/230\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.4718 - acc: 0.5784\n",
            "782/782 [==============================] - 1327s 2s/step - loss: 1.2710 - acc: 0.7111 - val_loss: 2.4718 - val_acc: 0.5784\n",
            "Epoch 229/230\n",
            "79/79 [==============================] - 19s 246ms/step - loss: 2.4500 - acc: 0.5877\n",
            "782/782 [==============================] - 1330s 2s/step - loss: 1.2707 - acc: 0.7123 - val_loss: 2.4500 - val_acc: 0.5877\n",
            "Epoch 230/230\n",
            "79/79 [==============================] - 19s 241ms/step - loss: 2.3867 - acc: 0.5755\n",
            "782/782 [==============================] - 1331s 2s/step - loss: 1.2614 - acc: 0.7145 - val_loss: 2.3867 - val_acc: 0.5755\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "-----------------------------------------Model weights and Logs saved to Google Drive-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTvKNSEtN6PJ",
        "colab_type": "text"
      },
      "source": [
        "# Final Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKrZlPoeFWzB",
        "colab_type": "text"
      },
      "source": [
        "**The best accuracy is 59.49% in epoch 198**"
      ]
    }
  ]
}